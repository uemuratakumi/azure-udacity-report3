{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameter Tuning using HyperDrive\n",
        "\n",
        "TODO: Import Dependencies. In the cell below, import all the dependencies that you will need to complete the project."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace, Experiment\r\n",
        "from azureml.core import Model \r\n",
        "from azureml.train.automl import AutoMLConfig\r\n",
        "from azureml.widgets import RunDetails\r\n",
        "from azureml.core.compute import ComputeTarget, AmlCompute\r\n",
        "from pprint import pprint \r\n",
        "import joblib\r\n",
        "import os"
      ],
      "outputs": [],
      "execution_count": 169,
      "metadata": {
        "gather": {
          "logged": 1688707884587
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile train.py\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "import sklearn.datasets\r\n",
        "import argparse\r\n",
        "import os\r\n",
        "import numpy as np\r\n",
        "import joblib\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.optimizers import Adam\r\n",
        "from tensorflow.keras.layers import Dense\r\n",
        "import pandas as pd\r\n",
        "from azureml.core.run import Run\r\n",
        "from azureml.data.dataset_factory import TabularDatasetFactory\r\n",
        "\r\n",
        "\r\n",
        "def make_data():\r\n",
        "    data  = sklearn.datasets.load_boston()\r\n",
        "    x = data.data\r\n",
        "    y = data.target\r\n",
        "    return x, y\r\n",
        "\r\n",
        "def main():\r\n",
        "    # Add arguments to script\r\n",
        "    parser = argparse.ArgumentParser()\r\n",
        "    parser.add_argument('--D', type=int, default=20, help=\"Inverse of regularization strength. Smaller values cause stronger regularization\")\r\n",
        "    parser.add_argument('--learningrate', type=float, default=0.001, help=\"Maximum number of iterations to converge\")\r\n",
        "    args = parser.parse_args()\r\n",
        "\r\n",
        "    run = Run.get_context()\r\n",
        "    run.log(\"Dense Number:\", np.float(args.D))\r\n",
        "    run.log(\"Learning Rate:\", np.int(args.learningrate))\r\n",
        "    x, y = make_data()\r\n",
        "\r\n",
        "    #Split data into train and test sets.\r\n",
        "    x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.3)\r\n",
        "\r\n",
        "    #make model\r\n",
        "    model = Sequential()\r\n",
        "    model.add(Dense(args.D, input_dim=13))\r\n",
        "    model.add(Dense(args.D, activation='relu'))\r\n",
        "    model.add(Dense(1))\r\n",
        "    model.compile(loss=\"mean_absolute_error\", optimizer=Adam(lr=args.learningrate))\r\n",
        "    model.summary()\r\n",
        "    validation_split_rate=0.2\r\n",
        "    history=model.fit(x_train,y_train,batch_size=16,epochs=100,validation_data=(x_test,y_test))\r\n",
        "\r\n",
        "    loss = model.evaluate(x_test, y_test)\r\n",
        "    run.log(\"Loss\", np.float(loss))\r\n",
        "    import joblib\r\n",
        "    # insert this after fitting the model\r\n",
        "    # create an output folder\r\n",
        "    os.makedirs('outputs', exist_ok=True)\r\n",
        "    model.save('outputs/model.h5')\r\n",
        "\r\n",
        "if __name__ == '__main__':\r\n",
        "    main()\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting train.py\n"
        }
      ],
      "execution_count": 170,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset\n",
        "\n",
        "TODO: Get data. In the cell below, write code to access the data you will be using in this project. Remember that the dataset needs to be external."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.datasets\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "import random\r\n",
        "import pandas as pd\r\n",
        "data  = sklearn.datasets.load_boston()\r\n",
        "df_X = pd.DataFrame(data.data, columns=data.feature_names)\r\n",
        "df_Y = pd.DataFrame(data.target, columns=['PRICE'])\r\n",
        "print(df_X)\r\n",
        "print(df_Y)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n0    0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n1    0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n2    0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n3    0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n4    0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n..       ...   ...    ...   ...    ...    ...   ...     ...  ...    ...   \n501  0.06263   0.0  11.93   0.0  0.573  6.593  69.1  2.4786  1.0  273.0   \n502  0.04527   0.0  11.93   0.0  0.573  6.120  76.7  2.2875  1.0  273.0   \n503  0.06076   0.0  11.93   0.0  0.573  6.976  91.0  2.1675  1.0  273.0   \n504  0.10959   0.0  11.93   0.0  0.573  6.794  89.3  2.3889  1.0  273.0   \n505  0.04741   0.0  11.93   0.0  0.573  6.030  80.8  2.5050  1.0  273.0   \n\n     PTRATIO       B  LSTAT  \n0       15.3  396.90   4.98  \n1       17.8  396.90   9.14  \n2       17.8  392.83   4.03  \n3       18.7  394.63   2.94  \n4       18.7  396.90   5.33  \n..       ...     ...    ...  \n501     21.0  391.99   9.67  \n502     21.0  396.90   9.08  \n503     21.0  396.90   5.64  \n504     21.0  393.45   6.48  \n505     21.0  396.90   7.88  \n\n[506 rows x 13 columns]\n     PRICE\n0     24.0\n1     21.6\n2     34.7\n3     33.4\n4     36.2\n..     ...\n501   22.4\n502   20.6\n503   23.9\n504   22.0\n505   11.9\n\n[506 rows x 1 columns]\n"
        }
      ],
      "execution_count": 171,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1688707889561
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ws = Workspace.from_config()\n",
        "experiment_name = 'exp_hyperdrive'\n",
        "experiment=Experiment(ws, experiment_name)\n",
        "run = experiment.start_logging()"
      ],
      "outputs": [],
      "execution_count": 172,
      "metadata": {
        "gather": {
          "logged": 1688707895956
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\r\n",
        "from azureml.core.compute_target import ComputeTargetException\r\n",
        "cluster_name = \"udacity-cluster\"\r\n",
        "\r\n",
        "#: Create compute cluster\r\n",
        "# Use vm_size = \"Standard_D2_V2\" in your provisioning configuration.\r\n",
        "# max_nodes should be no greater than 4.\r\n",
        "\r\n",
        "### YOUR CODE HERE ###\r\n",
        "vm_size = \"Standard_D2_V2\"\r\n",
        "# Check if the cluster already exists, and create it if it doesn't\r\n",
        "try:\r\n",
        "    compute_cluster = ComputeTarget(workspace=ws, name=cluster_name)\r\n",
        "    print(\"Using existing compute cluster.\")\r\n",
        "except ComputeTargetException:\r\n",
        "    compute_config = AmlCompute.provisioning_configuration(vm_size=vm_size, max_nodes=4)\r\n",
        "    compute_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\r\n",
        "\r\n",
        "compute_cluster.wait_for_completion(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "InProgress.\nSucceededProvisioning operation finished, operation \"Succeeded\"\nSucceeded\nAmlCompute wait for completion finished\n\nMinimum number of nodes requested have been provisioned\n"
        }
      ],
      "execution_count": 173,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1688707902453
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile conda_dependencies.yml\r\n",
        "dependencies:\r\n",
        "  - python=3.6.2\r\n",
        "  - tensorflow==2.0.0\r\n",
        "  - scikit-learn\r\n",
        "  - numpy\r\n",
        "  - pandas\r\n",
        "  - pip:\r\n",
        "    - azureml-defaults"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting conda_dependencies.yml\n"
        }
      ],
      "execution_count": 174,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperdrive Configuration\n",
        "\n",
        "TODO: Explain the model you are using and the reason for chosing the different hyperparameters, termination policy and config settings.\n",
        "\n",
        "In this project, MLP model is used for prediction.\n",
        "And I swing the two parameters that is number of dense matrix and learning raet.\n",
        "This is because the two parameters is affect to the accuracy of model.\n",
        "\n",
        "And I set early stopping policy strictly since this is not real project and I want to reduce learing cost.\n",
        "\n",
        "This target metrix of this project is loss of test data.\n",
        "The hypderdrive would try to minimize this."
      ],
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1598531923519
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.widgets import RunDetails\n",
        "from azureml.train.sklearn import SKLearn\n",
        "from azureml.train.hyperdrive.run import PrimaryMetricGoal\n",
        "from azureml.train.hyperdrive.policy import BanditPolicy\n",
        "from azureml.train.hyperdrive.sampling import RandomParameterSampling\n",
        "from azureml.train.hyperdrive.runconfig import HyperDriveConfig\n",
        "from azureml.train.hyperdrive.parameter_expressions import choice, uniform\n",
        "from azureml.core import Environment, ScriptRunConfig\n",
        "import os\n",
        "# TODO: Create an early termination policy. This is not required if you are using Bayesian sampling.\n",
        "early_termination_policy = BanditPolicy(slack_factor = 0.1, evaluation_interval = 1, delay_evaluation= 5 )\n",
        "\n",
        "if \"training\" not in os.listdir():\n",
        "    os.mkdir(\"./training\")\n",
        "\n",
        "#TODO: Create the different params that you will be using during training\n",
        "param_sampling = RandomParameterSampling(parameter_space={\n",
        "    '--D': choice(10, 20, 50, 100),\n",
        "    '--learningrate' : choice(0.01,0.001,0.0001)})\n",
        "\n",
        "# Setup environment for your training run\n",
        "tf_env = Environment.from_conda_specification(name='tf-env', file_path='conda_dependencies.yml')\n",
        "\n",
        "#TODO: Create your estimator and hyperdrive config\n",
        "estimator = ScriptRunConfig(source_directory=\".\",\n",
        "                      script=\"train.py\",\n",
        "                      compute_target=cluster_name,\n",
        "                      environment=tf_env)\n",
        "\n",
        "hyperdrive_run_config = HyperDriveConfig(\n",
        "    run_config = estimator, \n",
        "    hyperparameter_sampling = param_sampling,\n",
        "    policy = early_termination_policy,\n",
        "    primary_metric_name = \"Loss\",\n",
        "    primary_metric_goal = PrimaryMetricGoal.MINIMIZE,\n",
        "    max_total_runs = 6,\n",
        "    max_concurrent_runs = 4\n",
        "    )"
      ],
      "outputs": [],
      "execution_count": 175,
      "metadata": {
        "gather": {
          "logged": 1688707907569
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO: Submit your experiment\r\n",
        "hyperdrive_run = experiment.submit(hyperdrive_run_config, show_output=True)"
      ],
      "outputs": [],
      "execution_count": 176,
      "metadata": {
        "gather": {
          "logged": 1688707916475
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Details\n",
        "\n",
        "OPTIONAL: Write about the different models trained and their performance. Why do you think some models did better than others?\n",
        "\n",
        "TODO: In the cell below, use the `RunDetails` widget to show the different experiments."
      ],
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1598544898497
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RunDetails(hyperdrive_run).show()\r\n",
        "hyperdrive_run.wait_for_completion(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "_HyperDriveWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO'…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5b00c11db13d4a268d24923797171045"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/runs/HD_51552781-bb2d-4218-9203-c1a36be3f3d8?wsid=/subscriptions/8d1a13c1-dda4-4fdf-a927-e08a4213f4e3/resourcegroups/resoure-udacity/workspaces/ws-udacity&tid=71373672-464e-4725-990c-20c60c08821e\", \"run_id\": \"HD_51552781-bb2d-4218-9203-c1a36be3f3d8\", \"run_properties\": {\"run_id\": \"HD_51552781-bb2d-4218-9203-c1a36be3f3d8\", \"created_utc\": \"2023-07-07T05:31:58.870218Z\", \"properties\": {\"primary_metric_config\": \"{\\\"name\\\":\\\"Loss\\\",\\\"goal\\\":\\\"minimize\\\"}\", \"resume_from\": \"null\", \"runTemplate\": \"HyperDrive\", \"azureml.runsource\": \"hyperdrive\", \"platform\": \"AML\", \"ContentSnapshotId\": \"cb6a199c-4602-48e0-b40f-94c6ca428013\", \"user_agent\": \"python/3.8.5 (Linux-5.15.0-1035-azure-x86_64-with-glibc2.10) msrest/0.7.1 Hyperdrive.Service/1.0.0 Hyperdrive.SDK/core.1.49.0\", \"space_size\": \"12\", \"score\": \"3.3897126850328947\", \"best_child_run_id\": \"HD_51552781-bb2d-4218-9203-c1a36be3f3d8_0\", \"best_metric_status\": \"Succeeded\", \"best_data_container_id\": \"dcid.HD_51552781-bb2d-4218-9203-c1a36be3f3d8_0\"}, \"tags\": {\"_aml_system_max_concurrent_jobs\": \"4\", \"_aml_system_max_total_jobs\": \"6\", \"_aml_system_max_duration_minutes\": \"10080\", \"_aml_system_policy_config\": \"{\\\"name\\\":\\\"Bandit\\\",\\\"properties\\\":{\\\"evaluation_interval\\\":1,\\\"delay_evaluation\\\":5,\\\"slack_factor\\\":0.1}}\", \"_aml_system_generator_config\": \"{\\\"name\\\":\\\"RANDOM\\\",\\\"parameter_space\\\":{\\\"--D\\\":[\\\"choice\\\",[[10,20,50,100]]],\\\"--learningrate\\\":[\\\"choice\\\",[[0.01,0.001,0.0001]]]},\\\"properties\\\":null}\", \"_aml_system_primary_metric_config\": \"{\\\"name\\\":\\\"Loss\\\",\\\"goal\\\":\\\"minimize\\\"}\", \"_aml_system_platform_config\": \"{\\\"ServiceAddress\\\": \\\"https://japaneast.experiments.azureml.net\\\", \\\"SubscriptionId\\\": \\\"8d1a13c1-dda4-4fdf-a927-e08a4213f4e3\\\", \\\"ResourceGroupName\\\": \\\"resoure-udacity\\\", \\\"WorkspaceName\\\": \\\"ws-udacity\\\", \\\"ExperimentName\\\": \\\"exp_hyperdrive\\\", \\\"Definition\\\": {\\\"Configuration\\\": null, \\\"Attribution\\\": null, \\\"TelemetryValues\\\": {\\\"amlClientType\\\": \\\"azureml-sdk-train\\\", \\\"amlClientModule\\\": \\\"[Scrubbed]\\\", \\\"amlClientFunction\\\": \\\"[Scrubbed]\\\", \\\"tenantId\\\": \\\"71373672-464e-4725-990c-20c60c08821e\\\", \\\"amlClientRequestId\\\": \\\"e02f53ff-5f67-4317-9e0c-6710bdd48bc7\\\", \\\"amlClientSessionId\\\": \\\"66dba6f1-aded-4fe6-b4c6-bd7ccd01f502\\\", \\\"subscriptionId\\\": \\\"8d1a13c1-dda4-4fdf-a927-e08a4213f4e3\\\", \\\"estimator\\\": \\\"NoneType\\\", \\\"samplingMethod\\\": \\\"RANDOM\\\", \\\"terminationPolicy\\\": \\\"Bandit\\\", \\\"primaryMetricGoal\\\": \\\"minimize\\\", \\\"maxTotalRuns\\\": 6, \\\"maxConcurrentRuns\\\": 4, \\\"maxDurationMinutes\\\": 10080, \\\"vmSize\\\": null}, \\\"Overrides\\\": {\\\"Script\\\": \\\"train.py\\\", \\\"Command\\\": \\\"\\\", \\\"UseAbsolutePath\\\": false, \\\"Arguments\\\": [], \\\"SourceDirectoryDataStore\\\": null, \\\"Framework\\\": 0, \\\"Communicator\\\": 0, \\\"Target\\\": \\\"udacity-cluster\\\", \\\"DataReferences\\\": {}, \\\"Data\\\": {}, \\\"OutputData\\\": {}, \\\"Datacaches\\\": [], \\\"JobName\\\": null, \\\"MaxRunDurationSeconds\\\": 2592000, \\\"NodeCount\\\": 1, \\\"InstanceTypes\\\": [], \\\"Priority\\\": null, \\\"CredentialPassthrough\\\": false, \\\"Identity\\\": null, \\\"Environment\\\": {\\\"Name\\\": \\\"tf-env\\\", \\\"AutoRebuild\\\": true, \\\"Python\\\": {\\\"InterpreterPath\\\": \\\"python\\\", \\\"UserManagedDependencies\\\": false, \\\"CondaDependencies\\\": {\\\"dependencies\\\": [\\\"python=3.6.2\\\", \\\"tensorflow==2.0.0\\\", \\\"scikit-learn\\\", \\\"numpy\\\", \\\"pandas\\\", {\\\"pip\\\": [\\\"azureml-defaults\\\"]}]}, \\\"BaseCondaEnvironment\\\": null}, \\\"EnvironmentVariables\\\": {\\\"EXAMPLE_ENV_VAR\\\": \\\"EXAMPLE_VALUE\\\"}, \\\"Docker\\\": {\\\"BaseImage\\\": \\\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20230120.v1\\\", \\\"Platform\\\": {\\\"Os\\\": \\\"Linux\\\", \\\"Architecture\\\": \\\"amd64\\\"}, \\\"BaseDockerfile\\\": null, \\\"BaseImageRegistry\\\": {\\\"Address\\\": null, \\\"Username\\\": null, \\\"Password\\\": null}, \\\"Enabled\\\": false, \\\"Arguments\\\": []}, \\\"Spark\\\": {\\\"Repositories\\\": [], \\\"Packages\\\": [], \\\"PrecachePackages\\\": true}, \\\"InferencingStackVersion\\\": null}, \\\"History\\\": {\\\"OutputCollection\\\": true, \\\"DirectoriesToWatch\\\": [\\\"logs\\\"], \\\"EnableMLflowTracking\\\": true, \\\"snapshotProject\\\": true}, \\\"Spark\\\": {\\\"Configuration\\\": {\\\"spark.app.name\\\": \\\"Azure ML Experiment\\\", \\\"spark.yarn.maxAppAttempts\\\": \\\"1\\\"}}, \\\"ParallelTask\\\": {\\\"MaxRetriesPerWorker\\\": 0, \\\"WorkerCountPerNode\\\": 1, \\\"TerminalExitCodes\\\": null, \\\"Configuration\\\": {}}, \\\"BatchAi\\\": {\\\"NodeCount\\\": 0}, \\\"AmlCompute\\\": {\\\"Name\\\": null, \\\"VmSize\\\": null, \\\"RetainCluster\\\": false, \\\"ClusterMaxNodeCount\\\": null}, \\\"AISuperComputer\\\": {\\\"InstanceType\\\": \\\"D2\\\", \\\"FrameworkImage\\\": null, \\\"ImageVersion\\\": null, \\\"Location\\\": null, \\\"AISuperComputerStorageData\\\": null, \\\"Interactive\\\": false, \\\"ScalePolicy\\\": null, \\\"VirtualClusterArmId\\\": null, \\\"TensorboardLogDirectory\\\": null, \\\"SSHPublicKey\\\": null, \\\"SSHPublicKeys\\\": null, \\\"EnableAzmlInt\\\": true, \\\"Priority\\\": \\\"Medium\\\", \\\"SLATier\\\": \\\"Standard\\\", \\\"UserAlias\\\": null}, \\\"KubernetesCompute\\\": {\\\"InstanceType\\\": null}, \\\"Tensorflow\\\": {\\\"WorkerCount\\\": 1, \\\"ParameterServerCount\\\": 1}, \\\"Mpi\\\": {\\\"ProcessCountPerNode\\\": 1}, \\\"PyTorch\\\": {\\\"CommunicationBackend\\\": \\\"nccl\\\", \\\"ProcessCount\\\": null}, \\\"Hdi\\\": {\\\"YarnDeployMode\\\": 2}, \\\"ContainerInstance\\\": {\\\"Region\\\": null, \\\"CpuCores\\\": 2.0, \\\"MemoryGb\\\": 3.5}, \\\"ExposedPorts\\\": null, \\\"Docker\\\": {\\\"UseDocker\\\": false, \\\"SharedVolumes\\\": true, \\\"ShmSize\\\": \\\"2g\\\", \\\"Arguments\\\": []}, \\\"Cmk8sCompute\\\": {\\\"Configuration\\\": {}}, \\\"CommandReturnCodeConfig\\\": {\\\"ReturnCode\\\": 0, \\\"SuccessfulReturnCodes\\\": []}, \\\"EnvironmentVariables\\\": {}, \\\"ApplicationEndpoints\\\": {}, \\\"Parameters\\\": []}, \\\"SnapshotId\\\": \\\"cb6a199c-4602-48e0-b40f-94c6ca428013\\\", \\\"Snapshots\\\": [], \\\"SourceCodeDataReference\\\": null, \\\"ParentRunId\\\": null, \\\"DataContainerId\\\": null, \\\"RunType\\\": null, \\\"DisplayName\\\": null, \\\"EnvironmentAssetId\\\": null, \\\"Properties\\\": {}, \\\"Tags\\\": {}, \\\"AggregatedArtifactPath\\\": null}, \\\"ParentRunId\\\": \\\"HD_51552781-bb2d-4218-9203-c1a36be3f3d8\\\"}\", \"_aml_system_resume_child_runs\": \"null\", \"_aml_system_all_jobs_generated\": \"true\", \"_aml_system_cancellation_requested\": \"false\", \"_aml_system_progress_metadata_evaluation_timestamp\": \"\\\"2023-07-07T05:32:29.158288\\\"\", \"_aml_system_progress_metadata_digest\": \"\\\"0885729d5db36650ed1f0f5017c680f18fb2a3a806f5e62e29b4232b7d580455\\\"\", \"_aml_system_progress_metadata_active_timestamp\": \"\\\"2023-07-07T05:32:29.158288\\\"\", \"_aml_system_optimizer_state_artifact\": \"null\", \"_aml_system_outdated_optimizer_state_artifacts\": \"\\\"[]\\\"\", \"_aml_system_HD_51552781-bb2d-4218-9203-c1a36be3f3d8_0\": \"{\\\"--D\\\": 20, \\\"--learningrate\\\": 0.01}\", \"_aml_system_HD_51552781-bb2d-4218-9203-c1a36be3f3d8_1\": \"{\\\"--D\\\": 100, \\\"--learningrate\\\": 0.0001}\", \"_aml_system_HD_51552781-bb2d-4218-9203-c1a36be3f3d8_2\": \"{\\\"--D\\\": 50, \\\"--learningrate\\\": 0.0001}\", \"_aml_system_HD_51552781-bb2d-4218-9203-c1a36be3f3d8_3\": \"{\\\"--D\\\": 20, \\\"--learningrate\\\": 0.0001}\", \"_aml_system_HD_51552781-bb2d-4218-9203-c1a36be3f3d8_4\": \"{\\\"--D\\\": 50, \\\"--learningrate\\\": 0.01}\", \"_aml_system_HD_51552781-bb2d-4218-9203-c1a36be3f3d8_5\": \"{\\\"--D\\\": 100, \\\"--learningrate\\\": 0.001}\", \"_aml_system_final_best_metric_update_retry_count\": \"1\"}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": \"2023-07-07T05:38:04.953666Z\", \"status\": \"Completed\", \"log_files\": {\"azureml-logs/hyperdrive.txt\": \"https://wsudacity3201325855.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_51552781-bb2d-4218-9203-c1a36be3f3d8/azureml-logs/hyperdrive.txt?sv=2019-07-07&sr=b&sig=OiPOiXRcKVvarSk%2B95j7bkkpuEKSPqNeEAXqhUMZ6vY%3D&skoid=e7c7c170-118b-48d4-9519-5065d9e8a500&sktid=71373672-464e-4725-990c-20c60c08821e&skt=2023-07-07T04%3A57%3A59Z&ske=2023-07-08T13%3A07%3A59Z&sks=b&skv=2019-07-07&st=2023-07-07T06%3A00%3A16Z&se=2023-07-07T14%3A10%3A16Z&sp=r\"}, \"log_groups\": [[\"azureml-logs/hyperdrive.txt\"]], \"run_duration\": \"0:06:06\", \"run_number\": \"1688707918\", \"run_queued_details\": {\"status\": \"Completed\", \"details\": null}, \"hyper_parameters\": {\"--D\": [\"choice\", [[10, 20, 50, 100]]], \"--learningrate\": [\"choice\", [[0.01, 0.001, 0.0001]]]}}, \"child_runs\": [{\"run_id\": \"HD_51552781-bb2d-4218-9203-c1a36be3f3d8_1\", \"run_number\": 1688707920, \"metric\": 4.47381607, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2023-07-07T05:34:30.043847Z\", \"end_time\": \"2023-07-07T05:35:48.723666Z\", \"created_time\": \"2023-07-07T05:32:00.945072Z\", \"created_time_dt\": \"2023-07-07T05:32:00.945072Z\", \"duration\": \"0:03:47\", \"hyperdrive_id\": \"51552781-bb2d-4218-9203-c1a36be3f3d8\", \"arguments\": null, \"param_--D\": 100, \"param_--learningrate\": 0.0001, \"best_metric\": 4.47381607}, {\"run_id\": \"HD_51552781-bb2d-4218-9203-c1a36be3f3d8_3\", \"run_number\": 1688707921, \"metric\": 5.78059937, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2023-07-07T05:34:18.224287Z\", \"end_time\": \"2023-07-07T05:35:41.85879Z\", \"created_time\": \"2023-07-07T05:32:01.1686Z\", \"created_time_dt\": \"2023-07-07T05:32:01.1686Z\", \"duration\": \"0:03:40\", \"hyperdrive_id\": \"51552781-bb2d-4218-9203-c1a36be3f3d8\", \"arguments\": null, \"param_--D\": 20, \"param_--learningrate\": 0.0001, \"best_metric\": 4.47381607}, {\"run_id\": \"HD_51552781-bb2d-4218-9203-c1a36be3f3d8_5\", \"run_number\": 1688708190, \"metric\": 5.11998099, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2023-07-07T05:36:38.567335Z\", \"end_time\": \"2023-07-07T05:37:04.102105Z\", \"created_time\": \"2023-07-07T05:36:30.865479Z\", \"created_time_dt\": \"2023-07-07T05:36:30.865479Z\", \"duration\": \"0:00:33\", \"hyperdrive_id\": \"51552781-bb2d-4218-9203-c1a36be3f3d8\", \"arguments\": null, \"param_--D\": 100, \"param_--learningrate\": 0.001, \"best_metric\": 4.47381607}], \"children_metrics\": {\"categories\": [0], \"series\": {\"Dense Number:\": [{\"categories\": [1688707920, 1688707921, 1688708190], \"mode\": \"markers\", \"name\": \"Dense Number:\", \"stepped\": false, \"type\": \"scatter\", \"data\": [100.0, 20.0, 100.0]}, {\"categories\": [1688707920, 1688707921, 1688708190], \"mode\": \"lines\", \"name\": \"Dense Number:_min\", \"stepped\": true, \"type\": \"scatter\", \"data\": [100.0, 20.0, 20.0]}], \"Learning Rate:\": [{\"categories\": [1688707920, 1688707921, 1688708190], \"mode\": \"markers\", \"name\": \"Learning Rate:\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0, 0, 0]}, {\"categories\": [1688707920, 1688707921, 1688708190], \"mode\": \"lines\", \"name\": \"Learning Rate:_min\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0, 0, 0]}], \"Loss\": [{\"categories\": [1688707920, 1688707921, 1688708190], \"mode\": \"markers\", \"name\": \"Loss\", \"stepped\": false, \"type\": \"scatter\", \"data\": [4.4738160685489055, 5.780599368245978, 5.119980987749602]}, {\"categories\": [1688707920, 1688707921, 1688708190], \"mode\": \"lines\", \"name\": \"Loss_min\", \"stepped\": true, \"type\": \"scatter\", \"data\": [4.4738160685489055, 4.4738160685489055, 4.4738160685489055]}]}, \"metricName\": null, \"primaryMetricName\": \"Loss\", \"showLegend\": false}, \"run_metrics\": [{\"name\": \"best_child_by_primary_metric\", \"run_id\": \"HD_51552781-bb2d-4218-9203-c1a36be3f3d8\", \"categories\": [0], \"series\": [{\"data\": [{\"time_elapse\": [240, 273, 364], \"metric_value\": [5.780599368245978, 3.3897126850328947, 3.3897126850328947], \"metric_name\": [\"Loss\", \"Loss\", \"Loss\"], \"run_id\": [\"HD_51552781-bb2d-4218-9203-c1a36be3f3d8_3\", \"HD_51552781-bb2d-4218-9203-c1a36be3f3d8_0\", \"HD_51552781-bb2d-4218-9203-c1a36be3f3d8_0\"], \"final\": [false, false, true]}]}]}], \"run_logs\": \"[2023-07-07T05:31:59.917273][GENERATOR][INFO]Trying to sample '4' jobs from the hyperparameter space\\n[2023-07-07T05:32:00.5912200Z][SCHEDULER][INFO]Scheduling job, id='HD_51552781-bb2d-4218-9203-c1a36be3f3d8_0' \\n[2023-07-07T05:32:00.7012997Z][SCHEDULER][INFO]Scheduling job, id='HD_51552781-bb2d-4218-9203-c1a36be3f3d8_1' \\n[2023-07-07T05:32:00.8586529Z][SCHEDULER][INFO]Scheduling job, id='HD_51552781-bb2d-4218-9203-c1a36be3f3d8_2' \\n[2023-07-07T05:32:01.0344302Z][SCHEDULER][INFO]Scheduling job, id='HD_51552781-bb2d-4218-9203-c1a36be3f3d8_3' \\n[2023-07-07T05:32:01.0344734Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_51552781-bb2d-4218-9203-c1a36be3f3d8_0' \\n[2023-07-07T05:32:01.0429963Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_51552781-bb2d-4218-9203-c1a36be3f3d8_1' \\n[2023-07-07T05:32:00.980028][GENERATOR][INFO]Successfully sampled '4' jobs, they will soon be submitted to the execution target.\\n[2023-07-07T05:32:01.1121354Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_51552781-bb2d-4218-9203-c1a36be3f3d8_2' \\n[2023-07-07T05:32:01.2774730Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_51552781-bb2d-4218-9203-c1a36be3f3d8_3' \\n[2023-07-07T05:36:30.169506][GENERATOR][INFO]Trying to sample '2' jobs from the hyperparameter space\\n[2023-07-07T05:36:30.5183522Z][SCHEDULER][INFO]Scheduling job, id='HD_51552781-bb2d-4218-9203-c1a36be3f3d8_4' \\n[2023-07-07T05:36:30.6616553Z][SCHEDULER][INFO]Scheduling job, id='HD_51552781-bb2d-4218-9203-c1a36be3f3d8_5' \\n[2023-07-07T05:36:30.610702][GENERATOR][INFO]Successfully sampled '2' jobs, they will soon be submitted to the execution target.\\n[2023-07-07T05:36:30.7632242Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_51552781-bb2d-4218-9203-c1a36be3f3d8_4' \\n[2023-07-07T05:36:30.9526662Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_51552781-bb2d-4218-9203-c1a36be3f3d8_5' \\n[2023-07-07T05:37:00.326343][GENERATOR][INFO]All jobs generated.\\n[2023-07-07T05:37:00.172277][GENERATOR][INFO]Max number of jobs '6' reached for experiment.\\n[2023-07-07T05:38:05.559811][CONTROLLER][INFO]Experiment was 'ExperimentStatus.RUNNING', is 'ExperimentStatus.FINISHED'.\\n\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.49.0\"}, \"loading\": false}"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "RunId: HD_51552781-bb2d-4218-9203-c1a36be3f3d8\nWeb View: https://ml.azure.com/runs/HD_51552781-bb2d-4218-9203-c1a36be3f3d8?wsid=/subscriptions/8d1a13c1-dda4-4fdf-a927-e08a4213f4e3/resourcegroups/resoure-udacity/workspaces/ws-udacity&tid=71373672-464e-4725-990c-20c60c08821e\n\nStreaming azureml-logs/hyperdrive.txt\n=====================================\n\n[2023-07-07T05:31:59.917273][GENERATOR][INFO]Trying to sample '4' jobs from the hyperparameter space\n[2023-07-07T05:32:00.5912200Z][SCHEDULER][INFO]Scheduling job, id='HD_51552781-bb2d-4218-9203-c1a36be3f3d8_0' \n[2023-07-07T05:32:00.7012997Z][SCHEDULER][INFO]Scheduling job, id='HD_51552781-bb2d-4218-9203-c1a36be3f3d8_1' \n[2023-07-07T05:32:00.8586529Z][SCHEDULER][INFO]Scheduling job, id='HD_51552781-bb2d-4218-9203-c1a36be3f3d8_2' \n[2023-07-07T05:32:01.0344302Z][SCHEDULER][INFO]Scheduling job, id='HD_51552781-bb2d-4218-9203-c1a36be3f3d8_3' \n[2023-07-07T05:32:01.0344734Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_51552781-bb2d-4218-9203-c1a36be3f3d8_0' \n[2023-07-07T05:32:01.0429963Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_51552781-bb2d-4218-9203-c1a36be3f3d8_1' \n[2023-07-07T05:32:00.980028][GENERATOR][INFO]Successfully sampled '4' jobs, they will soon be submitted to the execution target.\n[2023-07-07T05:32:01.1121354Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_51552781-bb2d-4218-9203-c1a36be3f3d8_2' \n[2023-07-07T05:32:01.2774730Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_51552781-bb2d-4218-9203-c1a36be3f3d8_3' \n[2023-07-07T05:36:30.169506][GENERATOR][INFO]Trying to sample '2' jobs from the hyperparameter space\n[2023-07-07T05:36:30.5183522Z][SCHEDULER][INFO]Scheduling job, id='HD_51552781-bb2d-4218-9203-c1a36be3f3d8_4' \n[2023-07-07T05:36:30.6616553Z][SCHEDULER][INFO]Scheduling job, id='HD_51552781-bb2d-4218-9203-c1a36be3f3d8_5' \n[2023-07-07T05:36:30.610702][GENERATOR][INFO]Successfully sampled '2' jobs, they will soon be submitted to the execution target.\n[2023-07-07T05:36:30.7632242Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_51552781-bb2d-4218-9203-c1a36be3f3d8_4' \n[2023-07-07T05:36:30.9526662Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_51552781-bb2d-4218-9203-c1a36be3f3d8_5' \n[2023-07-07T05:37:00.326343][GENERATOR][INFO]All jobs generated.\n[2023-07-07T05:37:00.172277][GENERATOR][INFO]Max number of jobs '6' reached for experiment.\n[2023-07-07T05:38:05.559811][CONTROLLER][INFO]Experiment was 'ExperimentStatus.RUNNING', is 'ExperimentStatus.FINISHED'.\n\nExecution Summary\n=================\nRunId: HD_51552781-bb2d-4218-9203-c1a36be3f3d8\nWeb View: https://ml.azure.com/runs/HD_51552781-bb2d-4218-9203-c1a36be3f3d8?wsid=/subscriptions/8d1a13c1-dda4-4fdf-a927-e08a4213f4e3/resourcegroups/resoure-udacity/workspaces/ws-udacity&tid=71373672-464e-4725-990c-20c60c08821e\n\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 177,
          "data": {
            "text/plain": "{'runId': 'HD_51552781-bb2d-4218-9203-c1a36be3f3d8',\n 'target': 'udacity-cluster',\n 'status': 'Completed',\n 'startTimeUtc': '2023-07-07T05:31:58.961826Z',\n 'endTimeUtc': '2023-07-07T05:38:04.953666Z',\n 'services': {},\n 'properties': {'primary_metric_config': '{\"name\":\"Loss\",\"goal\":\"minimize\"}',\n  'resume_from': 'null',\n  'runTemplate': 'HyperDrive',\n  'azureml.runsource': 'hyperdrive',\n  'platform': 'AML',\n  'ContentSnapshotId': 'cb6a199c-4602-48e0-b40f-94c6ca428013',\n  'user_agent': 'python/3.8.5 (Linux-5.15.0-1035-azure-x86_64-with-glibc2.10) msrest/0.7.1 Hyperdrive.Service/1.0.0 Hyperdrive.SDK/core.1.49.0',\n  'space_size': '12',\n  'score': '3.3897126850328947',\n  'best_child_run_id': 'HD_51552781-bb2d-4218-9203-c1a36be3f3d8_0',\n  'best_metric_status': 'Succeeded',\n  'best_data_container_id': 'dcid.HD_51552781-bb2d-4218-9203-c1a36be3f3d8_0'},\n 'inputDatasets': [],\n 'outputDatasets': [],\n 'runDefinition': {'configuration': None,\n  'attribution': None,\n  'telemetryValues': {'amlClientType': 'azureml-sdk-train',\n   'amlClientModule': '[Scrubbed]',\n   'amlClientFunction': '[Scrubbed]',\n   'tenantId': '71373672-464e-4725-990c-20c60c08821e',\n   'amlClientRequestId': 'e02f53ff-5f67-4317-9e0c-6710bdd48bc7',\n   'amlClientSessionId': '66dba6f1-aded-4fe6-b4c6-bd7ccd01f502',\n   'subscriptionId': '8d1a13c1-dda4-4fdf-a927-e08a4213f4e3',\n   'estimator': 'NoneType',\n   'samplingMethod': 'RANDOM',\n   'terminationPolicy': 'Bandit',\n   'primaryMetricGoal': 'minimize',\n   'maxTotalRuns': 6,\n   'maxConcurrentRuns': 4,\n   'maxDurationMinutes': 10080,\n   'vmSize': None},\n  'snapshotId': 'cb6a199c-4602-48e0-b40f-94c6ca428013',\n  'snapshots': [],\n  'sourceCodeDataReference': None,\n  'parentRunId': None,\n  'dataContainerId': None,\n  'runType': None,\n  'displayName': None,\n  'environmentAssetId': None,\n  'properties': {},\n  'tags': {},\n  'aggregatedArtifactPath': None},\n 'logFiles': {'azureml-logs/hyperdrive.txt': 'https://wsudacity3201325855.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_51552781-bb2d-4218-9203-c1a36be3f3d8/azureml-logs/hyperdrive.txt?sv=2019-07-07&sr=b&sig=qFC3DG1QcSpd4%2BFreg0qm4%2BNdgFO3H3YtDVAHfZ7af4%3D&skoid=e7c7c170-118b-48d4-9519-5065d9e8a500&sktid=71373672-464e-4725-990c-20c60c08821e&skt=2023-07-07T03%3A54%3A11Z&ske=2023-07-08T12%3A04%3A11Z&sks=b&skv=2019-07-07&st=2023-07-07T05%3A28%3A25Z&se=2023-07-07T13%3A38%3A25Z&sp=r'},\n 'submittedBy': 'higashi higashi'}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 177,
      "metadata": {
        "gather": {
          "logged": 1688708335534
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Best Model\n",
        "\n",
        "TODO: In the cell below, get the best model from the hyperdrive experiments and display all the properties of the model."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "best_run = hyperdrive_run.get_best_run_by_primary_metric()\r\n",
        "best_run_metrics = best_run.get_metrics()\r\n",
        "parameter_values = best_run.get_details()['runDefinition']['arguments']\r\n",
        "print(best_run_metrics)\r\n",
        "print(parameter_values)\r\n",
        "print(best_run)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "{'Dense Number:': 20.0, 'Learning Rate:': 0, 'Loss': 3.3897126850328947}\n['--D', '20', '--learningrate', '0.01']\nRun(Experiment: exp_hyperdrive,\nId: HD_51552781-bb2d-4218-9203-c1a36be3f3d8_0,\nType: azureml.scriptrun,\nStatus: Completed)\n"
        }
      ],
      "execution_count": 191,
      "metadata": {
        "gather": {
          "logged": 1688709807831
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_run.get_file_names()\r\n",
        "index=best_run.get_file_names().index('outputs/model.h5')\r\n",
        "print(index)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "1\nCurrent provisioning state of AmlCompute is \"Deleting\"\n\nCurrent provisioning state of AmlCompute is \"Deleting\"\n\nCurrent provisioning state of AmlCompute is \"Deleting\"\n\nCurrent provisioning state of AmlCompute is \"Deleting\"\n\n"
        }
      ],
      "execution_count": 181,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1688708411986
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO: Save the best model\r\n",
        "best_run.download_file(best_run.get_file_names()[index], output_file_path='./outputs/')\r\n",
        "best_run.register_model(model_path='outputs/model.h5',model_name='hyperdrive_best')"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 185,
          "data": {
            "text/plain": "Model(workspace=Workspace.create(name='ws-udacity', subscription_id='8d1a13c1-dda4-4fdf-a927-e08a4213f4e3', resource_group='resoure-udacity'), name=hyperdrive_best, id=hyperdrive_best:1, version=1, tags={}, properties={})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 185,
      "metadata": {
        "gather": {
          "logged": 1688708455974
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Deployment\n",
        "\n",
        "Remember you have to deploy only one of the two models you trained but you still need to register both the models. Perform the steps in the rest of this notebook only if you wish to deploy this model.\n",
        "\n",
        "TODO: In the cell below, register the model, create an inference config and deploy the model as a web service."
      ],
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile score_boston.py\r\n",
        "import json\r\n",
        "import numpy as np\r\n",
        "import os\r\n",
        "from tensorflow.keras.models import load_model\r\n",
        "\r\n",
        "def init():\r\n",
        "    global model\r\n",
        "    # AZUREML_MODEL_DIR is an environment variable created during deployment.\r\n",
        "    # It is the path to the model folder (./azureml-models/$MODEL_NAME/$VERSION)\r\n",
        "    # For multiple models, it points to the folder containing all deployed models (./azureml-models)\r\n",
        "    model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'model.h5')\r\n",
        "    model = load_model(model_path)\r\n",
        "\r\n",
        "def run(raw_data):\r\n",
        "    data = np.array(json.loads(raw_data)['data'])\r\n",
        "    # make prediction\r\n",
        "    y_pred = model.predict(data)\r\n",
        "    # you can return any data type as long as it is JSON-serializable\r\n",
        "    return json.dumps(str(y_pred[0]))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting score_boston.py\n"
        }
      ],
      "execution_count": 186,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.webservice import AciWebservice\r\n",
        "from azureml.core.model import Model\r\n",
        "from azureml.core.model import InferenceConfig\r\n",
        "from azureml.core.environment import Environment\r\n",
        "aciconfig = AciWebservice.deploy_configuration(cpu_cores=1, \r\n",
        "                                               memory_gb=4, \r\n",
        "                                               description='Predict Boston House Price')\r\n",
        "\r\n",
        "inference_config = InferenceConfig(entry_script=\"score_boston.py\", environment=tf_env)\r\n",
        "service_name = 'udacity-report3-hyp3'\r\n",
        "model=ws.models['hyperdrivebest']\r\n",
        "\r\n",
        "service = Model.deploy(workspace=ws, \r\n",
        "                       name=service_name, \r\n",
        "                       models=[model],\r\n",
        "                       inference_config=inference_config,\r\n",
        "                       deployment_config=aciconfig)\r\n",
        "service.wait_for_deployment(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "azureml.core.model:\nTo leverage new model deployment capabilities, AzureML recommends using CLI/SDK v2 to deploy models as online endpoint, \nplease refer to respective documentations \nhttps://docs.microsoft.com/azure/machine-learning/how-to-deploy-managed-online-endpoints /\nhttps://docs.microsoft.com/azure/machine-learning/how-to-attach-kubernetes-anywhere \nFor more information on migration, see https://aka.ms/acimoemigration \nTo disable CLI/SDK v1 deprecation warning set AZUREML_LOG_DEPRECATION_WARNING_ENABLED to 'False'\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\nRunning\n2023-07-07 05:41:24+00:00 Creating Container Registry if not exists.\n2023-07-07 05:41:24+00:00 Registering the environment.\n2023-07-07 05:41:25+00:00 Use the existing image.\n2023-07-07 05:41:26+00:00 Submitting deployment to compute.\n2023-07-07 05:41:31+00:00 Checking the status of deployment udacity-report3-hyp3..\n2023-07-07 05:43:34+00:00 Checking the status of inference endpoint udacity-report3-hyp3.\nSucceeded\nACI service creation operation finished, operation \"Succeeded\"\n"
        }
      ],
      "execution_count": 187,
      "metadata": {
        "gather": {
          "logged": 1688708617473
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: In the cell below, send a request to the web service you deployed to test it."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\r\n",
        "import requests\r\n",
        "import json\r\n",
        "\r\n",
        "data  = sklearn.datasets.load_boston()\r\n",
        "x = data.data[0]\r\n",
        "\r\n",
        "endpoint='http://a4a50760-3fc6-4bb9-9d04-cd48c291a476.japaneast.azurecontainer.io/score'\r\n",
        "input_data=[x.tolist()]\r\n",
        "headers = {'Content-Type':'application/json'}\r\n",
        "input_json=json.dumps({\"data\":input_data})\r\n",
        "req=requests.post(endpoint,input_json,headers=headers)\r\n",
        "pred=json.loads(req.json())\r\n",
        "print('predict='+pred)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "predict=[33.91492]\n"
        }
      ],
      "execution_count": 189,
      "metadata": {
        "gather": {
          "logged": 1688708652826
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: In the cell below, print the logs of the web service and delete the service"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "print(service.get_logs())\r\n",
        "service.delete()\r\n",
        "compute_cluster.delete()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "2023-07-07T05:43:19,490016791+00:00 - gunicorn/run \n2023-07-07T05:43:19,491194718+00:00 | gunicorn/run | \n2023-07-07T05:43:19,492369345+00:00 | gunicorn/run | ###############################################\n2023-07-07T05:43:19,484958676+00:00 - rsyslog/run \n2023-07-07T05:43:19,497657665+00:00 | gunicorn/run | AzureML Container Runtime Information\n2023-07-07T05:43:19,484753271+00:00 - iot-server/run \n2023-07-07T05:43:19,500222424+00:00 | gunicorn/run | ###############################################\n2023-07-07T05:43:19,508604515+00:00 | gunicorn/run | \n2023-07-07T05:43:19,511593383+00:00 | gunicorn/run | \n2023-07-07T05:43:19,524263672+00:00 | gunicorn/run | AzureML image information: openmpi4.1.0-ubuntu20.04, Materializaton Build:20230120.v2\n2023-07-07T05:43:19,526843630+00:00 | gunicorn/run | \n2023-07-07T05:43:19,532217753+00:00 | gunicorn/run | \n2023-07-07T05:43:19,532820267+00:00 - nginx/run \n2023-07-07T05:43:19,534219199+00:00 | gunicorn/run | PATH environment variable: /azureml-envs/azureml_e86f1ad5f0d88a73b0e68d14996cdce2/bin:/opt/miniconda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\n2023-07-07T05:43:19,536500251+00:00 | gunicorn/run | PYTHONPATH environment variable: \n2023-07-07T05:43:19,543872119+00:00 | gunicorn/run | \n2023-07-07T05:43:19,546447577+00:00 | gunicorn/run | Pip Dependencies (before dynamic installation)\n\nEdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n2023-07-07T05:43:19,926664166+00:00 - iot-server/finish 1 0\n2023-07-07T05:43:19,930258852+00:00 - Exit code 1 is normal. Not restarting iot-server.\nabsl-py @ file:///opt/conda/conda-bld/absl-py_1639803114343/work\nadal==1.2.7\nargcomplete==2.1.2\nastor==0.8.1\nattrs==22.2.0\nazure-common==1.1.28\nazure-core==1.24.2\nazure-graphrbac==0.61.1\nazure-identity==1.7.0\nazure-mgmt-authorization==2.0.0\nazure-mgmt-containerregistry==10.0.0\nazure-mgmt-core==1.3.2\nazure-mgmt-keyvault==10.0.0\nazure-mgmt-resource==21.1.0\nazure-mgmt-storage==20.0.0\nazureml-core==1.47.0\nazureml-dataprep==4.5.7\nazureml-dataprep-native==38.0.0\nazureml-dataprep-rslex==2.11.4\nazureml-dataset-runtime==1.47.0\nazureml-defaults==1.47.0\nazureml-inference-server-http==0.7.7\nbackports.tempfile==1.0\nbackports.weakref==1.0.post1\nbcrypt==4.0.1\ncachetools==4.2.4\ncertifi==2021.5.30\ncffi==1.15.1\ncharset-normalizer==2.0.12\nclick==8.0.4\ncloudpickle==2.2.1\nconfigparser==3.7.4\ncontextlib2==21.6.0\ncontextvars==2.4\ncryptography==38.0.4\ndataclasses==0.8\ndistro==1.8.0\ndocker==5.0.3\ndotnetcore2==3.1.23\nFlask==2.0.3\nFlask-Cors==3.0.10\nfusepy==3.0.1\ngast==0.2.2\ngoogle-api-core==2.8.2\ngoogle-auth==2.21.0\ngoogle-pasta @ file:///Users/ktietz/demo/mc3/conda-bld/google-pasta_1630577991354/work\ngoogleapis-common-protos==1.56.3\ngrpcio==1.14.1\ngunicorn==20.1.0\nh5py @ file:///tmp/build/80754af9/h5py_1593454121459/work\nhumanfriendly==10.0\nidna==3.4\nimmutables==0.19\nimportlib-metadata @ file:///tmp/build/80754af9/importlib-metadata_1631916693255/work\ninference-schema==1.4.2.1\nisodate==0.6.1\nitsdangerous==2.0.1\njeepney==0.7.1\nJinja2==3.0.3\njmespath==0.10.0\njoblib @ file:///tmp/build/80754af9/joblib_1613502643832/work\njson-logging-py==0.2\njsonpickle==2.2.0\njsonschema==3.2.0\nKeras-Applications @ file:///tmp/build/80754af9/keras-applications_1594366238411/work\nKeras-Preprocessing @ file:///tmp/build/80754af9/keras-preprocessing_1612283640596/work\nknack==0.10.1\nMarkdown @ file:///tmp/build/80754af9/markdown_1614363833670/work\nMarkupSafe==2.0.1\nmkl-fft==1.3.0\nmkl-random==1.1.1\nmkl-service==2.3.0\nmsal==1.22.0\nmsal-extensions==0.3.1\nmsrest==0.7.1\nmsrestazure==0.6.4\nndg-httpsclient==0.5.1\nnumpy @ file:///tmp/build/80754af9/numpy_and_numpy_base_1603487797006/work\noauthlib==3.2.2\nopencensus==0.11.2\nopencensus-context==0.1.3\nopencensus-ext-azure==1.1.9\nopt-einsum @ file:///tmp/build/80754af9/opt_einsum_1621500238896/work\npackaging==21.3\npandas==1.1.5\nparamiko==2.12.0\npathspec==0.9.0\npkginfo==1.9.6\nportalocker==2.7.0\nprotobuf==3.17.2\npsutil==5.9.5\npyarrow==6.0.1\npyasn1==0.5.0\npyasn1-modules==0.3.0\npycparser==2.21\nPygments==2.14.0\nPyJWT==2.4.0\nPyNaCl==1.5.0\npyOpenSSL==22.1.0\npyparsing==3.0.7\npyrsistent==0.18.0\nPySocks==1.7.1\npython-dateutil @ file:///tmp/build/80754af9/python-dateutil_1626374649649/work\npytz==2021.3\nPyYAML==6.0\nrequests==2.27.1\nrequests-oauthlib==1.3.1\nrsa==4.9\nscikit-learn @ file:///tmp/build/80754af9/scikit-learn_1621365798935/work\nscipy @ file:///tmp/build/80754af9/scipy_1597686625380/work\nSecretStorage==3.3.3\nsix @ file:///tmp/build/80754af9/six_1644875935023/work\ntabulate==0.8.10\ntensorboard==2.0.0\ntensorflow==2.0.0\ntensorflow-estimator @ file:///home/builder/adipietro/tf/tensorflow-estimator_1630508970172/work/tensorflow_estimator-2.6.0-py2.py3-none-any.whl\ntermcolor==1.1.0\nthreadpoolctl @ file:///Users/ktietz/demo/mc3/conda-bld/threadpoolctl_1629802263681/work\ntyping_extensions @ file:///opt/conda/conda-bld/typing_extensions_1647553014482/work\nurllib3==1.26.16\nwebsocket-client==1.3.1\nWerkzeug==2.0.3\nwrapt==1.12.1\nzipp @ file:///tmp/build/80754af9/zipp_1633618647012/work\n\n2023-07-07T05:43:21,163841710+00:00 | gunicorn/run | \n2023-07-07T05:43:21,167295994+00:00 | gunicorn/run | ###############################################\n2023-07-07T05:43:21,169215940+00:00 | gunicorn/run | AzureML Inference Server\n2023-07-07T05:43:21,172983431+00:00 | gunicorn/run | ###############################################\n2023-07-07T05:43:21,174342264+00:00 | gunicorn/run | \n2023-07-07T05:43:23,117252433+00:00 | gunicorn/run | Starting AzureML Inference Server HTTP.\n\nAzure ML Inferencing HTTP server v0.7.7\n\n\nServer Settings\n---------------\nEntry Script Name: /var/azureml-app/score_boston.py\nModel Directory: /var/azureml-app/azureml-models/hyperdrivebest/1\nWorker Count: 1\nWorker Timeout (seconds): 300\nServer Port: 31311\nApplication Insights Enabled: false\nApplication Insights Key: None\nInferencing HTTP server version: azmlinfsrv/0.7.7\nCORS for the specified origins: None\n\n\nServer Routes\n---------------\nLiveness Probe: GET   127.0.0.1:31311/\nScore:          POST  127.0.0.1:31311/score\n\nStarting gunicorn 20.1.0\nListening at: http://0.0.0.0:31311 (80)\nUsing worker: sync\nBooting worker with pid: 143\nInitializing logger\n2023-07-07 05:43:24,500 | root | INFO | Starting up app insights client\nlogging socket was found. logging is available.\nlogging socket was found. logging is available.\n2023-07-07 05:43:24,500 | root | INFO | Starting up app insight hooks\n2023-07-07 05:43:27,804 | root | INFO | Found user script at /var/azureml-app/score_boston.py\n2023-07-07 05:43:27,805 | root | INFO | run() is not decorated. Server will invoke it with the input in JSON string.\n2023-07-07 05:43:27,805 | root | INFO | Invoking user's init function\n2023-07-07 05:43:27.836424: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\nTo enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\n2023-07-07 05:43:27.864005: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2593905000 Hz\n2023-07-07 05:43:27.864953: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5645c3c267e0 executing computations on platform Host. Devices:\n2023-07-07 05:43:27.865282: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\n2023-07-07 05:43:27.867924: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n2023-07-07 05:43:28,476 | root | INFO | Users's init has completed successfully\n/azureml-envs/azureml_e86f1ad5f0d88a73b0e68d14996cdce2/lib/python3.6/site-packages/azure/identity/_internal/aadclient_certificate.py:8: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography and will be removed in a future release.\n  from cryptography import x509\n2023-07-07 05:43:28,482 | root | INFO | Swaggers are prepared for the following versions: [2, 3].\n2023-07-07 05:43:28,483 | root | INFO | Scoring timeout is found from os.environ: 60000 ms\n2023-07-07 05:43:28,484 | root | INFO | AML_FLASK_ONE_COMPATIBILITY is set, but patching is not necessary.\n2023-07-07 05:43:34,383 | root | INFO | 200\n127.0.0.1 - - [07/Jul/2023:05:43:34 +0000] \"GET /swagger.json HTTP/1.0\" 200 2273 \"-\" \"Go-http-client/1.1\"\n2023-07-07 05:43:40,045 | root | INFO | 200\n127.0.0.1 - - [07/Jul/2023:05:43:40 +0000] \"GET /swagger.json HTTP/1.0\" 200 2273 \"-\" \"Go-http-client/1.1\"\n2023-07-07 05:43:57,011 | root | INFO | 200\n127.0.0.1 - - [07/Jul/2023:05:43:57 +0000] \"GET /swagger.json HTTP/1.0\" 200 2273 \"-\" \"Go-http-client/1.1\"\n2023-07-07 05:44:00,560 | root | INFO | 200\n127.0.0.1 - - [07/Jul/2023:05:44:00 +0000] \"GET /swagger.json HTTP/1.0\" 200 2273 \"-\" \"Go-http-client/1.1\"\n2023-07-07 05:44:15,910 | root | INFO | 200\n127.0.0.1 - - [07/Jul/2023:05:44:15 +0000] \"POST /score HTTP/1.0\" 200 16 \"-\" \"python-requests/2.28.2\"\n2023-07-07 05:47:16,332 | root | INFO | 200\n127.0.0.1 - - [07/Jul/2023:05:47:16 +0000] \"GET /swagger.json HTTP/1.0\" 200 2273 \"-\" \"Go-http-client/1.1\"\n\nCurrent provisioning state of AmlCompute is \"Deleting\"\n\n"
        }
      ],
      "execution_count": 190,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1688709017502
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Submission Checklist**\n",
        "- I have registered the model.\n",
        "- I have deployed the model with the best accuracy as a webservice.\n",
        "- I have tested the webservice by sending a request to the model endpoint.\n",
        "- I have deleted the webservice and shutdown all the computes that I have used.\n",
        "- I have taken a screenshot showing the model endpoint as active.\n",
        "- The project includes a file containing the environment details.\n",
        "\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {}
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}